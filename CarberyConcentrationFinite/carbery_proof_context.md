# Carbery's Inequality - Proof Strategy (CORRECTED)

Based on Terry Tao's blog post: "A generalized Cauchy-Schwarz inequality via the Gibbs variational formula" (December 2023).

**IMPORTANT CORRECTION**: The inequality uses COUNTING MEASURE norms (unweighted sums), NOT marginal-weighted norms. The previous formulation with marginal-weighted norms was DISPROVED.

## The Theorem (Finite Case - CORRECTED)

For finite state spaces Î©â‚€, ..., Î©â‚™â‚‹â‚, a joint PMF K, and functions fáµ¢ : Î©áµ¢ â†’ â„â‰¥0âˆ:

âˆ‘_x K(x) âˆáµ¢ fáµ¢(xáµ¢) â‰¤ Qâ‚™(K) Â· âˆáµ¢ â€–fáµ¢â€–_{L^{n+1}(counting)}

where:
- Qâ‚™(K) is the Carbery functional involving boundary marginals and consecutive bivariate marginals
- â€–fáµ¢â€–_{L^{n+1}(counting)} = (âˆ‘_s fáµ¢(s)^{n+1})^{1/(n+1)} is the COUNTING MEASURE norm (unweighted)

This is NOT the same as the marginal-weighted norm (âˆ‘_s Î¼áµ¢(s) Â· fáµ¢(s)^{n+1})^{1/(n+1)}.

## Proof Strategy 1: Induction with HÃ¶lder's Inequality

### Base Case (n=1)
For n=1, we need to show:
âˆ‘_{xâ‚€,xâ‚} K(xâ‚€,xâ‚) Â· fâ‚€(xâ‚€) Â· fâ‚(xâ‚) â‰¤ Qâ‚(K) Â· â€–fâ‚€â€–_{LÂ²} Â· â€–fâ‚â€–_{LÂ²}

where Qâ‚(K) involves the boundary marginals Kâ‚€, Kâ‚ and the joint K.

This follows from Cauchy-Schwarz applied appropriately.

### Inductive Step
Use HÃ¶lder's inequality to "integrate out" one variable at a time.

Key idea: Fix the last coordinate xâ‚™â‚‹â‚, apply the induction hypothesis to the remaining n-1 coordinates, then use HÃ¶lder to recombine.

## Proof Strategy 2: Gibbs Variational Formula (Tao's approach)

### Lemma (Gibbs Variational Formula)
For f: S â†’ â„ on finite set S:
log âˆ‘_{sâˆˆS} exp(f(s)) = sup_X [ğ”¼[f(X)] + H[X]]

where H[X] is Shannon entropy and the sup is over all probability distributions on S.

### Key Insight
Take logarithms of both sides of Carbery's inequality and use the variational formula.
This reduces the inequality to a statement about conditional entropy.

### Lemma (Entropy Identity)
For tuples (Xâ‚€,...,Xâ‚™â‚‹â‚) satisfying certain constraints:
H[Xâ‚€,...,Xâ‚™â‚‹â‚] â‰¤ sum of individual and pairwise entropies

This is proven by induction, using the chain rule for entropy:
H[X,Y] = H[X] + H[Y|X]

### The Logarithmic Form
Taking logs, the inequality becomes:
log(âˆ‘_x K(x) âˆáµ¢ fáµ¢(xáµ¢)) â‰¤ (1/(n+1)) Â· log(Qâ‚™^{n+1}(K)) + âˆ‘áµ¢ (1/(n+1)) Â· log(âˆ‘_s fáµ¢(s)^{n+1})

## Key Mathlib Lemmas

- `ENNReal.inner_le_Lp_mul_Lq` - HÃ¶lder's inequality for ENNReal
- `ENNReal.rpow_add`, `ENNReal.rpow_mul` - Power arithmetic
- `Finset.sum_product`, `Finset.prod_mul_distrib` - Sum/product manipulation
- `Real.inner_le_Lp_mul_Lq` - HÃ¶lder's inequality for Real
- `NNReal.inner_le_Lp_mul_Lq` - HÃ¶lder's inequality for NNReal

## Proof Sketch for Lean

1. **Induction on n**
2. **Base case n=1**: Apply Cauchy-Schwarz
   - The key is showing Qâ‚(K) Â· â€–fâ‚€â€–_{LÂ²} Â· â€–fâ‚â€–_{LÂ²} bounds the bilinear form
3. **Inductive step**:
   - Fix the last coordinate xâ‚™â‚‹â‚
   - Apply induction hypothesis to the remaining n-1 coordinates
   - Use HÃ¶lder's inequality with exponents (n+1, (n+1)/n) to recombine
   - Show the Carbery functional structure correctly captures the dependencies

## Alternative: Direct Verification for Small n

For n=2:
âˆ‘_{xâ‚€,xâ‚,xâ‚‚} K(xâ‚€,xâ‚,xâ‚‚) Â· fâ‚€(xâ‚€) Â· fâ‚(xâ‚) Â· fâ‚‚(xâ‚‚) â‰¤ Qâ‚‚(K) Â· â€–fâ‚€â€–_{LÂ³} Â· â€–fâ‚â€–_{LÂ³} Â· â€–fâ‚‚â€–_{LÂ³}

Use HÃ¶lder with exponents (3, 3, 3) after appropriate manipulation.

## References

- Carbery, A. (2004). "A multilinear generalisation of the Cauchy-Schwarz inequality". Proc. Amer. Math. Soc.
- Tao, T. (2023). "A generalized Cauchy-Schwarz inequality via the Gibbs variational formula". Blog post.
